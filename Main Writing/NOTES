p1

You mention Hodgkin, Huxley, and Katz, but don't reference any paper by Huxley (only one by Hodgkin and Katz).

p3

Research focused in the neocortex refer to cortical circuits,
a general term for larger neuronal networks located in the cortex and cortical ensembles, referring
to coactive networks of neurons that possibly comprise cortical circuits -- this is potentially the most interesting thought here, and had I seen it before, I'd advised you to expand it. It's too late now, but at the very least know that that's the most interesting part of the whole story, and also an interesting topic to discuss. (I personally am not going to ask you about it, but it sort of prompts to be asked about; it sounds so interesting, and is not quite covered in the text itself)

p4

Overall, without details, and based only on your explanation, I'm not quite sure how these studies relate to the question of local network connectivity. Based on your description, they sound like generic fMRI studies; maybe looking at redistribution of activation across different areas in development, but there's nothing in this paragraph to suggest that it relates to the topic of your sproj. Do they use similar math? Or do they actually relate their research to local connectivity? That's another question a board member might ask.

For example, cliques, or all-to-all
connected networks, of neuronal populations have been studied as a method of relating structural
to functional connectivities of neuronal populations. -- semantically incorrect. Cliques are abstract objects, not methods. The ending of the sentence is very general, and sort of universally applicable. It is not clear to the reader what's so special about cliques in particular. And we have the weak word "relate" again. Overall, another place where a reader would be tempted to ask a follow-up question.

In the context of neuronal networks, cliques
are further studied as directed cliques. -- It feels like you are hinting at directed graphs without actually introducing them, which is risky.

p5

The reconstruction
and viewing of networks as compositions of cliques suggests that -- logically dubious. When you try to describe a network as a series of cliques, this approach may work or not. Yet you are writing that the approach itself (essentially, a method) suggsts something about the nature of networks in the brain. This is confusing. The fact that a method works may tell you something about the nature of the network, but I am not qutie sure whether this is what you are trying to say.

A network following a
power-law distribution -- without a formal definition of degree, and a formula for the "power-law", I don't think an uninitiated reader would be able to understand you

p10

The first paragraph on this page sounds as if you're reintroducing the motivation for your study, but I cannot quite figure the logic of it. You start with large-scale methods, then talk about "representation" of networks, and then mention machine learning. Not sure how these three are related.

While these reconstruction methods use di erent methods for evaluating
activity and connectivity, they are typically applied to simulated neuron populations, where the
ground truth of the activity is known, allowing evaluation on the accuracy of the model -- a very questionable sentence. If a reconstruction method can only be applied to modeling data, this method doesn't exist. If it is only applied to situations where it is not needed, it means that it failed. Another place where a reader would ask a follow-up question.

p11

I'd say you need a formula for granger causality if you're introducing it.

In brief, the researchers demonstrate -- you don't have any citations here. Once you mention "research", the reader would expect the sentence to end with 2-3 references.

p12

While Turing's test is a fascinating topic, I'm not sure how it fits in this story. Feels a bit confusing, to be honest.

p13

Auto-encoders -- you casually mention a new fancy word without introducing it, and without a reference

p14

On gradient descent: it feels that you're introducing the history of the question without actually explaining what the method is about, how it works, and what the actual developments were. When reading this, I didn't realize that you actually explain it one page lower. Please add somewhere here a sentence, or an aside, saying that it is introduced and explained below. Like in "Gradient descent method (introduced and explained below)  bla bla bla". Something like that.

p15

I think you're describing stochastic gradient descent, but you don't seem to be using this term.

p32

I'm not quite sure what is happening in this figure. Are you comparing inferred degree distributions to the ground truth? Or should I compare a to e, and d to f? How to read it? Please try to clarify the caption if you can.

p33

So the figure seems to suggest that some neurons are connected to all other neurons. That's something a random reader would probably have questions about, so even if you aren't discussing it in the text, it could be prudent to be ready to discuss it at the board. (I won't be asking these questions; I'm too invested, but if I were not your advisor, that would totally be my question)

-----> Personal Note = I'm going to answer this at the board

p34

This whole ROC discussion is cool, but it feels a bit like something that could be first introduced in the methods, or in the introduction.

p35

Mention in the figure caption where these figures came from. Which simulations did you use to produce them? Also the figures are missing axes labels. I also recommend to remind the reader in the caption what words like "Base" and "Activatoin" mean here.

I'm also rather confused why cross-correlation performed as random guessing in your models. It's really cool that you have these curves in your sproj, but that would be another obvious question to ask. Usually x-correlation still gives you a bend above the y=x line; why wan't it a case here?

p36

You describe degree distribution in a random network, but it is just a model you chose to test your newly developed method. The distribution itself doesn't mean anything: it is you who chose it. This is a good section for the "methods" section, but arguably not for the discussion. 

In the discussion, it would be better to discuss whether your network managed ot reconstruct this degree distribution, whatever it was. Was it close? Was it easy? How did it fare?

p38

Future work seems quite promising; not quite clear, but intriguing and promising, I like it.
